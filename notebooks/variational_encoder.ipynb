{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), os.pardir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from src.tools.preprocess import preprocess_data\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "from skimage import exposure\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/code/python/zindi/AAIS-AI/zindi_telangana_crop_health_challenge/src/tools/preprocess.py:58: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '3943.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_clean.loc[non_null_mask & outlier_mask, col] = clean_mean\n",
      "/home/paul/code/python/zindi/AAIS-AI/zindi_telangana_crop_health_challenge/src/tools/preprocess.py:58: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1301674.4039252088' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_clean.loc[non_null_mask & outlier_mask, col] = clean_mean\n",
      "/home/paul/code/python/zindi/AAIS-AI/zindi_telangana_crop_health_challenge/src/tools/preprocess.py:58: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '77.4192444219067' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_clean.loc[non_null_mask & outlier_mask, col] = clean_mean\n",
      "/home/paul/code/python/zindi/AAIS-AI/zindi_telangana_crop_health_challenge/src/tools/preprocess.py:58: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '85.36429030186255' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_clean.loc[non_null_mask & outlier_mask, col] = clean_mean\n",
      "/home/paul/code/python/zindi/AAIS-AI/zindi_telangana_crop_health_challenge/src/tools/preprocess.py:58: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '3.538159229208925' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_clean.loc[non_null_mask & outlier_mask, col] = clean_mean\n",
      "/home/paul/code/python/zindi/AAIS-AI/zindi_telangana_crop_health_challenge/src/tools/preprocess.py:58: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '57.15428498985801' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_clean.loc[non_null_mask & outlier_mask, col] = clean_mean\n",
      "/home/paul/code/python/zindi/AAIS-AI/zindi_telangana_crop_health_challenge/src/tools/preprocess.py:58: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '15.69447261663286' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_clean.loc[non_null_mask & outlier_mask, col] = clean_mean\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>FarmID</th>\n",
       "      <th>category</th>\n",
       "      <th>Crop</th>\n",
       "      <th>State</th>\n",
       "      <th>District</th>\n",
       "      <th>Sub-District</th>\n",
       "      <th>SDate</th>\n",
       "      <th>HDate</th>\n",
       "      <th>CropCoveredArea</th>\n",
       "      <th>...</th>\n",
       "      <th>ndwi</th>\n",
       "      <th>gndvi</th>\n",
       "      <th>savi</th>\n",
       "      <th>msavi</th>\n",
       "      <th>SDate_year</th>\n",
       "      <th>SDate_month</th>\n",
       "      <th>SDate_day</th>\n",
       "      <th>HDate_year</th>\n",
       "      <th>HDate_month</th>\n",
       "      <th>HDate_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1326576.0</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>Paddy</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>Medak</td>\n",
       "      <td>Kulcharam</td>\n",
       "      <td>2023-11-25</td>\n",
       "      <td>2024-04-14</td>\n",
       "      <td>97.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.488031</td>\n",
       "      <td>0.127153</td>\n",
       "      <td>0.151125</td>\n",
       "      <td>4232.596191</td>\n",
       "      <td>2023</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1326577.0</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>Paddy</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>Medak</td>\n",
       "      <td>Kulcharam</td>\n",
       "      <td>2023-11-13</td>\n",
       "      <td>2024-04-26</td>\n",
       "      <td>82.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.493762</td>\n",
       "      <td>0.187815</td>\n",
       "      <td>0.282110</td>\n",
       "      <td>3249.392822</td>\n",
       "      <td>2023</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1326578.0</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>Paddy</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>Medak</td>\n",
       "      <td>Kulcharam</td>\n",
       "      <td>2023-12-19</td>\n",
       "      <td>2024-04-28</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.166884</td>\n",
       "      <td>0.206553</td>\n",
       "      <td>0.309869</td>\n",
       "      <td>3741.956055</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1331836.0</td>\n",
       "      <td>Diseased</td>\n",
       "      <td>Paddy</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>Medak</td>\n",
       "      <td>Kulcharam</td>\n",
       "      <td>2023-02-11</td>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.446196</td>\n",
       "      <td>0.220995</td>\n",
       "      <td>0.309350</td>\n",
       "      <td>3673.396729</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1326579.0</td>\n",
       "      <td>Diseased</td>\n",
       "      <td>Paddy</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>Medak</td>\n",
       "      <td>Kulcharam</td>\n",
       "      <td>2023-12-12</td>\n",
       "      <td>2024-05-19</td>\n",
       "      <td>94.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.665929</td>\n",
       "      <td>0.160657</td>\n",
       "      <td>0.269563</td>\n",
       "      <td>4227.338379</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     FarmID  category   Crop      State District Sub-District  \\\n",
       "0         0.0  1326576.0   Healthy  Paddy  Telangana    Medak    Kulcharam   \n",
       "1         1.0  1326577.0   Healthy  Paddy  Telangana    Medak    Kulcharam   \n",
       "2         2.0  1326578.0   Healthy  Paddy  Telangana    Medak    Kulcharam   \n",
       "3         3.0  1331836.0  Diseased  Paddy  Telangana    Medak    Kulcharam   \n",
       "4         4.0  1326579.0  Diseased  Paddy  Telangana    Medak    Kulcharam   \n",
       "\n",
       "       SDate      HDate  CropCoveredArea  ...       ndwi     gndvi      savi  \\\n",
       "0 2023-11-25 2024-04-14             97.0  ...   8.488031  0.127153  0.151125   \n",
       "1 2023-11-13 2024-04-26             82.0  ...  11.493762  0.187815  0.282110   \n",
       "2 2023-12-19 2024-04-28             92.0  ...  10.166884  0.206553  0.309869   \n",
       "3 2023-02-11 2024-11-04             91.0  ...  10.446196  0.220995  0.309350   \n",
       "4 2023-12-12 2024-05-19             94.0  ...   8.665929  0.160657  0.269563   \n",
       "\n",
       "         msavi SDate_year SDate_month  SDate_day  HDate_year  HDate_month  \\\n",
       "0  4232.596191       2023          11         25        2024            4   \n",
       "1  3249.392822       2023          11         13        2024            4   \n",
       "2  3741.956055       2023          12         19        2024            4   \n",
       "3  3673.396729       2023           2         11        2024           11   \n",
       "4  4227.338379       2023          12         12        2024            5   \n",
       "\n",
       "  HDate_day  \n",
       "0        14  \n",
       "1        26  \n",
       "2        28  \n",
       "3         4  \n",
       "4        19  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/processed/data.csv')\n",
    "data_clean, anomalies = preprocess_data(data[data[\"dataset\"] == \"train\"])\n",
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def scale_band(band):\n",
    "    \"\"\"Scale band data to 0-255.\"\"\"\n",
    "    band_min = np.min(band)\n",
    "    band_max = np.max(band)\n",
    "    return ((band - band_min) / (band_max - band_min) * 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "class TiffDataset(Dataset):\n",
    "    def __init__(self, directory, data, type=\"train\", transform=None, gamma=0.6, contrast_stretch=True):\n",
    "        self.directory = directory\n",
    "        self.transform = transform\n",
    "        self.gamma = gamma\n",
    "        self.contrast_stretch = contrast_stretch\n",
    "        self.images = data.loc[(data[\"tif_path\"].str.endswith('.tif')) & (data[\"dataset\"] == type),\n",
    "                               \"tif_path\"\n",
    "                               ].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.directory, self.images[idx])\n",
    "\n",
    "        # Open the image file\n",
    "        with rasterio.open(img_path) as src:\n",
    "            # Read RGB bands (assuming Sentinel-2 band order: Red=B4, Green=B3, Blue=B2)\n",
    "            red = src.read(3)\n",
    "            green = src.read(2)\n",
    "            blue = src.read(1)\n",
    "            # Stack the scaled RGB bands into a single image\n",
    "            rgb = np.dstack((red, green,\n",
    "                            blue)).astype(np.uint8)\n",
    "\n",
    "            # Convert NumPy array to PIL Image\n",
    "            rgb = Image.fromarray(rgb)\n",
    "\n",
    "            if self.transform:\n",
    "                rgb = self.transform(rgb)\n",
    "\n",
    "        return rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((16, 16)),\n",
    "    transforms.RandomRotation(degrees=30),\n",
    "    transforms.RandomAffine(translate=(0.1, 0.1), degrees=20),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = TiffDataset(\n",
    "    directory=\"../data\", data=data_clean, type=\"train\", transform=transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_dataset = TiffDataset(\n",
    "    directory=\"../data\", data=data_clean, type=\"test\", transform=transform)\n",
    "test_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(3, 64, 3, stride=2, padding=1),  # 32x32 -> 16x16\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "            torch.nn.Dropout(0.2),\n",
    "\n",
    "            torch.nn.Conv2d(64, 128, 3, stride=2, padding=1),  # 16x16 -> 8x8\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm2d(128),\n",
    "            torch.nn.Dropout(0.2),\n",
    "\n",
    "            torch.nn.Conv2d(128, 256, 3, stride=2, padding=1),  # 8x8 -> 4x4\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm2d(256),\n",
    "            torch.nn.Flatten(),\n",
    "\n",
    "            torch.nn.Linear(256 * 2 * 2, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.2),\n",
    "\n",
    "            torch.nn.Linear(64, 5)  # Code latent réduit à 4\n",
    "        )\n",
    "\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(5, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.3),\n",
    "\n",
    "            torch.nn.Linear(64, 256 * 2 * 2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm1d(256 * 2 * 2),\n",
    "\n",
    "            torch.nn.Unflatten(1, (256, 2, 2)),\n",
    "            torch.nn.ConvTranspose2d(\n",
    "                256, 128, 3, stride=2, padding=1, output_padding=1),  # 4x4 -> 8x8\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm2d(128),\n",
    "\n",
    "            torch.nn.ConvTranspose2d(\n",
    "                128, 64, 3, stride=2, padding=1, output_padding=1),   # 8x8 -> 16x16\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "\n",
    "            torch.nn.ConvTranspose2d(\n",
    "                64, 3, 3, stride=2, padding=1, output_padding=1),    # 16x16 -> 32x32\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUDA-capable device(s) is/are busy or unavailable\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m autoencoder \u001b[38;5;241m=\u001b[39m \u001b[43mAutoencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/telangana-crop-health-challenge-Bgz_xKMH-py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1340\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1337\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1338\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/telangana-crop-health-challenge-Bgz_xKMH-py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/telangana-crop-health-challenge-Bgz_xKMH-py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/telangana-crop-health-challenge-Bgz_xKMH-py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:927\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 927\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    930\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/telangana-crop-health-challenge-Bgz_xKMH-py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1326\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1321\u001b[0m             device,\n\u001b[1;32m   1322\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1323\u001b[0m             non_blocking,\n\u001b[1;32m   1324\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1325\u001b[0m         )\n\u001b[0;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUDA-capable device(s) is/are busy or unavailable\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "autoencoder = Autoencoder().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "telangana-crop-health-challenge-Bgz_xKMH-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
